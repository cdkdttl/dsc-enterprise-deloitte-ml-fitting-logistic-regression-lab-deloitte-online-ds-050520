{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting a Logistic Regression Model - Lab\n",
    "\n",
    "## Introduction\n",
    "You were previously given a broad overview of logistic regression. This included two separate packages for creating logistic regression models. In this lab, you'll be investigating fitting logistic regressions with statsmodels.\n",
    "\n",
    "\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "* Implement logistic regression with statsmodels\n",
    "* Interpret the statistical results associated with regression model parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review\n",
    "\n",
    "The statsmodels example we covered had four essential parts:\n",
    "* Importing the data\n",
    "* Defining X and y\n",
    "* Fitting the model\n",
    "* Analyzing model results\n",
    "\n",
    "The corresponding code to these four steps was:\n",
    "\n",
    "```\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#Step 1: Importing the data\n",
    "salaries = pd.read_csv(\"salaries_final.csv\", index_col = 0)\n",
    "\n",
    "#Step 2: Defining X and y\n",
    "x_feats = [\"Race\", \"Sex\", \"Age\"]\n",
    "X = pd.get_dummies(salaries[x_feats], drop_first=True, dtype=float)\n",
    "y = pd.get_dummies(salaries[\"Target\"], dtype=float)\n",
    "\n",
    "#Step 3: Fitting the model\n",
    "X = sm.add_constant(X)\n",
    "logit_model = sm.Logit(y.iloc[:,1], X)\n",
    "result = logit_model.fit()\n",
    "\n",
    "#Step 4: Analyzing model results\n",
    "result.summary()\n",
    "```\n",
    "\n",
    "Most of this should be fairly familiar to you; importing data with Pandas, initializing a regression object, and calling the fit method of that object. However, step 2 warrants a slightly more in depth explanation.\n",
    "\n",
    "Recall that we fit the salary data using `Race`, `Sex`, and `Age`. Since `Race` and `Sex` are categorical, we converted them to dummy variables using the `get_dummies()` method. The ```get_dummies()``` method will only convert `object` and `category` data types to dummy variables so it is safe to pass `Age`. Note that we also passed two additional arguments, ```drop_first=True``` and ```dtype=float```. The ```drop_first=True``` argument removes the first level for each categorical variable and the ```dtype=float``` argument converts the data type of all of the dummy variables to float. The data must be float in order to obtain accurate statistical results from statsmodel. Finally, note that y itself returns a pandas DataFrame with two columns as y itself was originally a categorical variable. With that, it's time to try and define a logistic regression model on your own!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Turn - Step 1: Import the Data\n",
    "\n",
    "Import the data stored in the file **titanic.csv**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels as sm\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"titanic.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000  C123        S  \n",
       "5                0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define X and Y\n",
    "\n",
    "For your first foray into logistic regression, you are going to attempt to build a model that classifies whether an individual survived the Titanic shipwreck or not (yes it's a bit morbid). Follow the programming patterns described above to define X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 2])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['Pclass','Sex','Age','Parch']].nunique()\n",
    "data['Pclass'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "x_feats = ['Pclass','Sex','Parch','Cabin','Embarked'] #age didn't work\n",
    "X = pd.get_dummies(data[x_feats], drop_first=True, dtype=float)\n",
    "y = pd.get_dummies(data[\"Survived\"], dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Fit the model\n",
    "\n",
    "Now with everything in place, initialize a regression object and fit your model!\n",
    "\n",
    "### Warning: If you receive an error of the form \"LinAlgError: Singular matrix\"\n",
    "\n",
    "Statsmodels was unable to fit the model due to some Linear Algebra problems. Specifically, the matrix was not invertible due to not being full rank. In layman's terms, there was a lot of redundant, superfluous data. Try removing some features from the model and running it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.368159\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/learn-env/lib/python3.6/site-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# create intercept term required for sm.Logit, see documentation for more information\n",
    "X = sm.add_constant(X)\n",
    "# fit model\n",
    "logit_model = sm.Logit(y.iloc[:,1], X)\n",
    "# get results of the fit\n",
    "result = logit_model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Analyzing results\n",
    "\n",
    "Generate the summary table for your model. Then, comment on the p-values associated with the various features you chose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>1</td>        <th>  No. Observations:  </th>  <td>   891</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   739</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>   151</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 12 May 2020</td> <th>  Pseudo R-squ.:     </th>  <td>0.4471</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>02:13:46</td>     <th>  Log-Likelihood:    </th> <td> -328.03</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>False</td>      <th>  LL-Null:           </th> <td> -593.33</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>1.088e-43</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>               <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                 <td>    3.2627</td> <td>    0.506</td> <td>    6.453</td> <td> 0.000</td> <td>    2.272</td> <td>    4.254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pclass</th>                <td>   -0.7833</td> <td>    0.168</td> <td>   -4.667</td> <td> 0.000</td> <td>   -1.112</td> <td>   -0.454</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Parch</th>                 <td>   -0.1565</td> <td>    0.117</td> <td>   -1.339</td> <td> 0.181</td> <td>   -0.386</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sex_male</th>              <td>   -2.6831</td> <td>    0.214</td> <td>  -12.550</td> <td> 0.000</td> <td>   -3.102</td> <td>   -2.264</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_A14</th>             <td>  -20.7277</td> <td> 4.64e+04</td> <td>   -0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_A16</th>             <td>   19.0060</td> <td> 4.63e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.07e+04</td> <td> 9.07e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_A19</th>             <td>  -20.7277</td> <td> 4.64e+04</td> <td>   -0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_A20</th>             <td>   21.6944</td> <td> 4.64e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td>  9.1e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_A23</th>             <td>   22.2531</td> <td> 4.64e+04</td> <td>    0.000</td> <td> 1.000</td> <td> -9.1e+04</td> <td>  9.1e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_A24</th>             <td>  -20.7277</td> <td> 4.64e+04</td> <td>   -0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_A26</th>             <td>   21.6944</td> <td> 4.64e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td>  9.1e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_A31</th>             <td>   21.6944</td> <td> 4.64e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td>  9.1e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_A32</th>             <td>  -20.7277</td> <td> 4.64e+04</td> <td>   -0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_A34</th>             <td>   22.5668</td> <td> 4.65e+04</td> <td>    0.000</td> <td> 1.000</td> <td> -9.1e+04</td> <td> 9.11e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_A36</th>             <td>  -20.7277</td> <td> 4.64e+04</td> <td>   -0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_A5</th>              <td>  -21.2864</td> <td> 4.64e+04</td> <td>   -0.000</td> <td> 1.000</td> <td> -9.1e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_A6</th>              <td>   22.2531</td> <td> 4.64e+04</td> <td>    0.000</td> <td> 1.000</td> <td> -9.1e+04</td> <td>  9.1e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_A7</th>              <td>  -21.2864</td> <td> 4.64e+04</td> <td>   -0.000</td> <td> 1.000</td> <td> -9.1e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_B101</th>            <td>   21.6944</td> <td> 4.64e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td>  9.1e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_B102</th>            <td>  -20.7277</td> <td> 4.64e+04</td> <td>   -0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_B18</th>             <td>   15.3187</td> <td> 4789.946</td> <td>    0.003</td> <td> 0.997</td> <td>-9372.802</td> <td> 9403.440</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_B19</th>             <td>  -20.7277</td> <td> 4.64e+04</td> <td>   -0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_B20</th>             <td>   19.0051</td> <td> 8856.139</td> <td>    0.002</td> <td> 0.998</td> <td>-1.73e+04</td> <td> 1.74e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_B22</th>             <td>   -0.3456</td> <td>    1.735</td> <td>   -0.199</td> <td> 0.842</td> <td>   -3.746</td> <td>    3.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_B28</th>             <td>   15.1621</td> <td> 4789.645</td> <td>    0.003</td> <td> 0.997</td> <td>-9372.369</td> <td> 9402.693</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_B3</th>              <td>   19.7215</td> <td> 4.63e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.08e+04</td> <td> 9.08e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_B30</th>             <td>  -21.1295</td> <td> 4.64e+04</td> <td>   -0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_B35</th>             <td>   15.1621</td> <td> 4789.645</td> <td>    0.003</td> <td> 0.997</td> <td>-9372.369</td> <td> 9402.693</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_B37</th>             <td>  -21.2864</td> <td> 4.64e+04</td> <td>   -0.000</td> <td> 1.000</td> <td> -9.1e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_B38</th>             <td>  -20.7277</td> <td> 4.64e+04</td> <td>   -0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_B39</th>             <td>   19.3197</td> <td> 4.63e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.07e+04</td> <td> 9.08e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_B4</th>              <td>   19.0060</td> <td> 4.63e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.07e+04</td> <td> 9.07e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_B41</th>             <td>   21.8513</td> <td> 4.64e+04</td> <td>    0.000</td> <td> 1.000</td> <td> -9.1e+04</td> <td>  9.1e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_B42</th>             <td>   19.5646</td> <td> 4.63e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.08e+04</td> <td> 9.08e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_B49</th>             <td>   18.4236</td> <td> 8750.777</td> <td>    0.002</td> <td> 0.998</td> <td>-1.71e+04</td> <td> 1.72e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_B5</th>              <td>   17.4738</td> <td> 1.11e+04</td> <td>    0.002</td> <td> 0.999</td> <td>-2.16e+04</td> <td> 2.17e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_B50</th>             <td>   21.6944</td> <td> 4.64e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td>  9.1e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_B51 B53 B55</th>     <td>    0.5607</td> <td>    1.450</td> <td>    0.387</td> <td> 0.699</td> <td>   -2.282</td> <td>    3.404</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_B57 B59 B63 B66</th> <td>   15.4754</td> <td> 4790.261</td> <td>    0.003</td> <td> 0.997</td> <td>-9373.263</td> <td> 9404.214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_B58 B60</th>         <td>   -0.9814</td> <td>    1.780</td> <td>   -0.551</td> <td> 0.581</td> <td>   -4.470</td> <td>    2.508</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_B69</th>             <td>   19.7215</td> <td> 4.63e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.08e+04</td> <td> 9.08e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_B71</th>             <td>  -20.7277</td> <td> 4.64e+04</td> <td>   -0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_B73</th>             <td>   19.5646</td> <td> 4.63e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.08e+04</td> <td> 9.08e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_B77</th>             <td>   15.7203</td> <td> 4790.983</td> <td>    0.003</td> <td> 0.997</td> <td>-9374.434</td> <td> 9405.875</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_B78</th>             <td>   19.0060</td> <td> 4.63e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.07e+04</td> <td> 9.07e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_B79</th>             <td>   19.5646</td> <td> 4.63e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.08e+04</td> <td> 9.08e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_B80</th>             <td>   19.0060</td> <td> 4.63e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.07e+04</td> <td> 9.07e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_B82 B84</th>         <td>  -21.2864</td> <td> 4.64e+04</td> <td>   -0.000</td> <td> 1.000</td> <td> -9.1e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_B86</th>             <td>  -21.2864</td> <td> 4.64e+04</td> <td>   -0.000</td> <td> 1.000</td> <td> -9.1e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_B94</th>             <td>  -20.7277</td> <td> 4.64e+04</td> <td>   -0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_B96 B98</th>         <td>   22.1625</td> <td>  2.6e+04</td> <td>    0.001</td> <td> 0.999</td> <td>-5.09e+04</td> <td> 5.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C101</th>            <td>   19.5646</td> <td> 4.63e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.08e+04</td> <td> 9.08e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C103</th>            <td>   19.5646</td> <td> 4.63e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.08e+04</td> <td> 9.08e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C104</th>            <td>   22.2531</td> <td> 4.64e+04</td> <td>    0.000</td> <td> 1.000</td> <td> -9.1e+04</td> <td>  9.1e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C106</th>            <td>   22.2531</td> <td> 4.64e+04</td> <td>    0.000</td> <td> 1.000</td> <td> -9.1e+04</td> <td>  9.1e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C110</th>            <td>  -20.7277</td> <td> 4.64e+04</td> <td>   -0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C111</th>            <td>  -21.2864</td> <td> 4.64e+04</td> <td>   -0.000</td> <td> 1.000</td> <td> -9.1e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C118</th>            <td>  -21.1295</td> <td> 4.64e+04</td> <td>   -0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C123</th>            <td>   -0.5803</td> <td>    1.768</td> <td>   -0.328</td> <td> 0.743</td> <td>   -4.045</td> <td>    2.884</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C124</th>            <td>  -16.8817</td> <td> 4793.029</td> <td>   -0.004</td> <td> 0.997</td> <td>-9411.046</td> <td> 9377.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C125</th>            <td>   17.4738</td> <td> 1.11e+04</td> <td>    0.002</td> <td> 0.999</td> <td>-2.16e+04</td> <td> 2.17e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C126</th>            <td>   19.0051</td> <td> 8856.139</td> <td>    0.002</td> <td> 0.998</td> <td>-1.73e+04</td> <td> 1.74e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C128</th>            <td>  -20.7277</td> <td> 4.64e+04</td> <td>   -0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C148</th>            <td>   21.6944</td> <td> 4.64e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td>  9.1e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C2</th>              <td>   -0.5803</td> <td>    1.768</td> <td>   -0.328</td> <td> 0.743</td> <td>   -4.045</td> <td>    2.884</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C22 C26</th>         <td>   -1.7239</td> <td>    1.390</td> <td>   -1.240</td> <td> 0.215</td> <td>   -4.449</td> <td>    1.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C23 C25 C27</th>     <td>   -0.1928</td> <td>    1.318</td> <td>   -0.146</td> <td> 0.884</td> <td>   -2.776</td> <td>    2.391</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C30</th>             <td>  -20.7277</td> <td> 4.64e+04</td> <td>   -0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C32</th>             <td>   19.0060</td> <td> 4.63e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.07e+04</td> <td> 9.07e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C45</th>             <td>   19.0060</td> <td> 4.63e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.07e+04</td> <td> 9.07e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C46</th>             <td>  -20.7277</td> <td> 4.64e+04</td> <td>   -0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C47</th>             <td>   21.6944</td> <td> 4.64e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td>  9.1e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C49</th>             <td>  -23.9748</td> <td> 4.65e+04</td> <td>   -0.001</td> <td> 1.000</td> <td>-9.12e+04</td> <td> 9.12e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C50</th>             <td>   19.1628</td> <td> 4.63e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.07e+04</td> <td> 9.08e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C52</th>             <td>   18.4053</td> <td> 4795.642</td> <td>    0.004</td> <td> 0.997</td> <td>-9380.880</td> <td> 9417.691</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C54</th>             <td>   19.0060</td> <td> 4.63e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.07e+04</td> <td> 9.07e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C62 C64</th>         <td>   19.0060</td> <td> 4.63e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.07e+04</td> <td> 9.07e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C65</th>             <td>   -1.1379</td> <td>    1.778</td> <td>   -0.640</td> <td> 0.522</td> <td>   -4.624</td> <td>    2.348</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C68</th>             <td>   -0.9814</td> <td>    1.780</td> <td>   -0.551</td> <td> 0.581</td> <td>   -4.470</td> <td>    2.508</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C7</th>              <td>   19.8783</td> <td> 4.63e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.08e+04</td> <td> 9.08e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C70</th>             <td>   22.0081</td> <td> 4.64e+04</td> <td>    0.000</td> <td> 1.000</td> <td> -9.1e+04</td> <td>  9.1e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C78</th>             <td>   -0.9832</td> <td>    1.799</td> <td>   -0.547</td> <td> 0.585</td> <td>   -4.509</td> <td>    2.542</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C82</th>             <td>  -20.9727</td> <td> 4.64e+04</td> <td>   -0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C83</th>             <td>   -0.5803</td> <td>    1.768</td> <td>   -0.328</td> <td> 0.743</td> <td>   -4.045</td> <td>    2.884</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C85</th>             <td>   19.0060</td> <td> 4.63e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.07e+04</td> <td> 9.07e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C86</th>             <td>  -21.2864</td> <td> 4.64e+04</td> <td>   -0.000</td> <td> 1.000</td> <td> -9.1e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C87</th>             <td>  -20.7277</td> <td> 4.64e+04</td> <td>   -0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C90</th>             <td>   19.0060</td> <td> 4.63e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.07e+04</td> <td> 9.07e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C91</th>             <td>  -20.5709</td> <td> 4.64e+04</td> <td>   -0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C92</th>             <td>   18.4236</td> <td> 8750.777</td> <td>    0.002</td> <td> 0.998</td> <td>-1.71e+04</td> <td> 1.72e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C93</th>             <td>   19.0051</td> <td> 8856.139</td> <td>    0.002</td> <td> 0.998</td> <td>-1.73e+04</td> <td> 1.74e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C95</th>             <td>  -20.7277</td> <td> 4.64e+04</td> <td>   -0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_C99</th>             <td>   19.5646</td> <td> 4.63e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.08e+04</td> <td> 9.08e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_D</th>               <td>    0.2519</td> <td>    1.445</td> <td>    0.174</td> <td> 0.862</td> <td>   -2.581</td> <td>    3.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_D10 D12</th>         <td>   21.8513</td> <td> 4.64e+04</td> <td>    0.000</td> <td> 1.000</td> <td> -9.1e+04</td> <td>  9.1e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_D11</th>             <td>   19.5646</td> <td> 4.63e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.08e+04</td> <td> 9.08e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_D15</th>             <td>   19.0060</td> <td> 4.63e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.07e+04</td> <td> 9.07e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_D17</th>             <td>   15.7203</td> <td> 4790.983</td> <td>    0.003</td> <td> 0.997</td> <td>-9374.434</td> <td> 9405.875</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_D19</th>             <td>   22.2531</td> <td> 4.64e+04</td> <td>    0.000</td> <td> 1.000</td> <td> -9.1e+04</td> <td>  9.1e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_D20</th>             <td>   15.1621</td> <td> 4789.645</td> <td>    0.003</td> <td> 0.997</td> <td>-9372.369</td> <td> 9402.693</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_D21</th>             <td>   19.5646</td> <td> 4.63e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.08e+04</td> <td> 9.08e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_D26</th>             <td>  -16.7251</td> <td> 4792.722</td> <td>   -0.003</td> <td> 0.997</td> <td>-9410.287</td> <td> 9376.837</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_D28</th>             <td>   19.7215</td> <td> 4.63e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.08e+04</td> <td> 9.08e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_D30</th>             <td>  -20.7277</td> <td> 4.64e+04</td> <td>   -0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_D33</th>             <td>   18.4236</td> <td> 8750.777</td> <td>    0.002</td> <td> 0.998</td> <td>-1.71e+04</td> <td> 1.72e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_D35</th>             <td>   19.1672</td> <td> 8880.769</td> <td>    0.002</td> <td> 0.998</td> <td>-1.74e+04</td> <td> 1.74e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_D36</th>             <td>   15.1621</td> <td> 4789.645</td> <td>    0.003</td> <td> 0.997</td> <td>-9372.369</td> <td> 9402.693</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_D37</th>             <td>   19.0060</td> <td> 4.63e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.07e+04</td> <td> 9.07e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_D45</th>             <td>   22.2531</td> <td> 4.64e+04</td> <td>    0.000</td> <td> 1.000</td> <td> -9.1e+04</td> <td>  9.1e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_D46</th>             <td>  -20.7277</td> <td> 4.64e+04</td> <td>   -0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_D47</th>             <td>   19.8783</td> <td> 4.63e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.08e+04</td> <td> 9.08e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_D48</th>             <td>  -20.9727</td> <td> 4.64e+04</td> <td>   -0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_D49</th>             <td>   21.6944</td> <td> 4.64e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td>  9.1e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_D50</th>             <td>  -20.7277</td> <td> 4.64e+04</td> <td>   -0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_D56</th>             <td>   23.0382</td> <td> 4.65e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.11e+04</td> <td> 9.11e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_D6</th>              <td>  -20.7277</td> <td> 4.64e+04</td> <td>   -0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_D7</th>              <td>   19.5646</td> <td> 4.63e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.08e+04</td> <td> 9.08e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_D9</th>              <td>   19.5646</td> <td> 4.63e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.08e+04</td> <td> 9.08e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_E10</th>             <td>   23.8233</td> <td> 4.65e+04</td> <td>    0.001</td> <td> 1.000</td> <td>-9.12e+04</td> <td> 9.12e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_E101</th>            <td>   23.3595</td> <td> 1.28e+05</td> <td>    0.000</td> <td> 1.000</td> <td> -2.5e+05</td> <td> 2.51e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_E12</th>             <td>   22.2531</td> <td> 4.64e+04</td> <td>    0.000</td> <td> 1.000</td> <td> -9.1e+04</td> <td>  9.1e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_E121</th>            <td>   20.7737</td> <td> 9060.190</td> <td>    0.002</td> <td> 0.998</td> <td>-1.77e+04</td> <td> 1.78e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_E17</th>             <td>   22.2531</td> <td> 4.64e+04</td> <td>    0.000</td> <td> 1.000</td> <td> -9.1e+04</td> <td>  9.1e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_E24</th>             <td>   18.4053</td> <td> 4795.642</td> <td>    0.004</td> <td> 0.997</td> <td>-9380.880</td> <td> 9417.691</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_E25</th>             <td>   18.4053</td> <td> 4795.642</td> <td>    0.004</td> <td> 0.997</td> <td>-9380.880</td> <td> 9417.691</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_E31</th>             <td>  -20.7277</td> <td> 4.64e+04</td> <td>   -0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_E33</th>             <td>   15.8769</td> <td> 4791.296</td> <td>    0.003</td> <td> 0.997</td> <td>-9374.891</td> <td> 9406.644</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_E34</th>             <td>   19.1628</td> <td> 4.63e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.07e+04</td> <td> 9.08e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_E36</th>             <td>   19.0060</td> <td> 4.63e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.07e+04</td> <td> 9.07e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_E38</th>             <td>  -20.7277</td> <td> 4.64e+04</td> <td>   -0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_E40</th>             <td>   19.0060</td> <td> 4.63e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.07e+04</td> <td> 9.07e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_E44</th>             <td>   -0.5803</td> <td>    1.768</td> <td>   -0.328</td> <td> 0.743</td> <td>   -4.045</td> <td>    2.884</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_E46</th>             <td>  -20.7277</td> <td> 4.64e+04</td> <td>   -0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_E49</th>             <td>   19.1628</td> <td> 4.63e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.07e+04</td> <td> 9.08e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_E50</th>             <td>   21.6944</td> <td> 4.64e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td>  9.1e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_E58</th>             <td>  -20.7277</td> <td> 4.64e+04</td> <td>   -0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_E63</th>             <td>  -20.7277</td> <td> 4.64e+04</td> <td>   -0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_E67</th>             <td>   -0.4238</td> <td>    1.769</td> <td>   -0.240</td> <td> 0.811</td> <td>   -3.891</td> <td>    3.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_E68</th>             <td>   19.8783</td> <td> 4.63e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.08e+04</td> <td> 9.08e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_E77</th>             <td>  -22.6310</td> <td> 4.65e+04</td> <td>   -0.000</td> <td> 1.000</td> <td>-9.11e+04</td> <td>  9.1e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_E8</th>              <td>   19.0051</td> <td> 8856.139</td> <td>    0.002</td> <td> 0.998</td> <td>-1.73e+04</td> <td> 1.74e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_F E69</th>           <td>   20.7331</td> <td> 4.64e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_F G63</th>           <td>  -19.1575</td> <td> 4.63e+04</td> <td>   -0.000</td> <td> 1.000</td> <td>-9.07e+04</td> <td> 9.07e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_F G73</th>           <td>  -15.3139</td> <td> 4790.050</td> <td>   -0.003</td> <td> 0.997</td> <td>-9403.639</td> <td> 9373.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_F2</th>              <td>    2.4472</td> <td>    1.245</td> <td>    1.966</td> <td> 0.049</td> <td>    0.007</td> <td>    4.887</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_F33</th>             <td>   26.0038</td> <td> 4.52e+05</td> <td> 5.75e-05</td> <td> 1.000</td> <td>-8.86e+05</td> <td> 8.86e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_F38</th>             <td>  -19.5615</td> <td> 4.63e+04</td> <td>   -0.000</td> <td> 1.000</td> <td>-9.08e+04</td> <td> 9.08e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_F4</th>              <td>   19.9703</td> <td> 8969.642</td> <td>    0.002</td> <td> 0.998</td> <td>-1.76e+04</td> <td> 1.76e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_G6</th>              <td>   -0.1597</td> <td>    1.016</td> <td>   -0.157</td> <td> 0.875</td> <td>   -2.152</td> <td>    1.832</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cabin_T</th>               <td>  -20.7277</td> <td> 4.64e+04</td> <td>   -0.000</td> <td> 1.000</td> <td>-9.09e+04</td> <td> 9.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Embarked_Q</th>            <td>   -0.1547</td> <td>    0.399</td> <td>   -0.387</td> <td> 0.698</td> <td>   -0.937</td> <td>    0.628</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Embarked_S</th>            <td>   -0.5576</td> <td>    0.276</td> <td>   -2.023</td> <td> 0.043</td> <td>   -1.098</td> <td>   -0.017</td>\n",
       "</tr>\n",
       "</table><br/><br/>Possibly complete quasi-separation: A fraction 0.18 of observations can be<br/>perfectly predicted. This might indicate that there is complete<br/>quasi-separation. In this case some parameters will not be identified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      1   No. Observations:                  891\n",
       "Model:                          Logit   Df Residuals:                      739\n",
       "Method:                           MLE   Df Model:                          151\n",
       "Date:                Tue, 12 May 2020   Pseudo R-squ.:                  0.4471\n",
       "Time:                        02:13:46   Log-Likelihood:                -328.03\n",
       "converged:                      False   LL-Null:                       -593.33\n",
       "Covariance Type:            nonrobust   LLR p-value:                 1.088e-43\n",
       "=========================================================================================\n",
       "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------\n",
       "const                     3.2627      0.506      6.453      0.000       2.272       4.254\n",
       "Pclass                   -0.7833      0.168     -4.667      0.000      -1.112      -0.454\n",
       "Parch                    -0.1565      0.117     -1.339      0.181      -0.386       0.073\n",
       "Sex_male                 -2.6831      0.214    -12.550      0.000      -3.102      -2.264\n",
       "Cabin_A14               -20.7277   4.64e+04     -0.000      1.000   -9.09e+04    9.09e+04\n",
       "Cabin_A16                19.0060   4.63e+04      0.000      1.000   -9.07e+04    9.07e+04\n",
       "Cabin_A19               -20.7277   4.64e+04     -0.000      1.000   -9.09e+04    9.09e+04\n",
       "Cabin_A20                21.6944   4.64e+04      0.000      1.000   -9.09e+04     9.1e+04\n",
       "Cabin_A23                22.2531   4.64e+04      0.000      1.000    -9.1e+04     9.1e+04\n",
       "Cabin_A24               -20.7277   4.64e+04     -0.000      1.000   -9.09e+04    9.09e+04\n",
       "Cabin_A26                21.6944   4.64e+04      0.000      1.000   -9.09e+04     9.1e+04\n",
       "Cabin_A31                21.6944   4.64e+04      0.000      1.000   -9.09e+04     9.1e+04\n",
       "Cabin_A32               -20.7277   4.64e+04     -0.000      1.000   -9.09e+04    9.09e+04\n",
       "Cabin_A34                22.5668   4.65e+04      0.000      1.000    -9.1e+04    9.11e+04\n",
       "Cabin_A36               -20.7277   4.64e+04     -0.000      1.000   -9.09e+04    9.09e+04\n",
       "Cabin_A5                -21.2864   4.64e+04     -0.000      1.000    -9.1e+04    9.09e+04\n",
       "Cabin_A6                 22.2531   4.64e+04      0.000      1.000    -9.1e+04     9.1e+04\n",
       "Cabin_A7                -21.2864   4.64e+04     -0.000      1.000    -9.1e+04    9.09e+04\n",
       "Cabin_B101               21.6944   4.64e+04      0.000      1.000   -9.09e+04     9.1e+04\n",
       "Cabin_B102              -20.7277   4.64e+04     -0.000      1.000   -9.09e+04    9.09e+04\n",
       "Cabin_B18                15.3187   4789.946      0.003      0.997   -9372.802    9403.440\n",
       "Cabin_B19               -20.7277   4.64e+04     -0.000      1.000   -9.09e+04    9.09e+04\n",
       "Cabin_B20                19.0051   8856.139      0.002      0.998   -1.73e+04    1.74e+04\n",
       "Cabin_B22                -0.3456      1.735     -0.199      0.842      -3.746       3.055\n",
       "Cabin_B28                15.1621   4789.645      0.003      0.997   -9372.369    9402.693\n",
       "Cabin_B3                 19.7215   4.63e+04      0.000      1.000   -9.08e+04    9.08e+04\n",
       "Cabin_B30               -21.1295   4.64e+04     -0.000      1.000   -9.09e+04    9.09e+04\n",
       "Cabin_B35                15.1621   4789.645      0.003      0.997   -9372.369    9402.693\n",
       "Cabin_B37               -21.2864   4.64e+04     -0.000      1.000    -9.1e+04    9.09e+04\n",
       "Cabin_B38               -20.7277   4.64e+04     -0.000      1.000   -9.09e+04    9.09e+04\n",
       "Cabin_B39                19.3197   4.63e+04      0.000      1.000   -9.07e+04    9.08e+04\n",
       "Cabin_B4                 19.0060   4.63e+04      0.000      1.000   -9.07e+04    9.07e+04\n",
       "Cabin_B41                21.8513   4.64e+04      0.000      1.000    -9.1e+04     9.1e+04\n",
       "Cabin_B42                19.5646   4.63e+04      0.000      1.000   -9.08e+04    9.08e+04\n",
       "Cabin_B49                18.4236   8750.777      0.002      0.998   -1.71e+04    1.72e+04\n",
       "Cabin_B5                 17.4738   1.11e+04      0.002      0.999   -2.16e+04    2.17e+04\n",
       "Cabin_B50                21.6944   4.64e+04      0.000      1.000   -9.09e+04     9.1e+04\n",
       "Cabin_B51 B53 B55         0.5607      1.450      0.387      0.699      -2.282       3.404\n",
       "Cabin_B57 B59 B63 B66    15.4754   4790.261      0.003      0.997   -9373.263    9404.214\n",
       "Cabin_B58 B60            -0.9814      1.780     -0.551      0.581      -4.470       2.508\n",
       "Cabin_B69                19.7215   4.63e+04      0.000      1.000   -9.08e+04    9.08e+04\n",
       "Cabin_B71               -20.7277   4.64e+04     -0.000      1.000   -9.09e+04    9.09e+04\n",
       "Cabin_B73                19.5646   4.63e+04      0.000      1.000   -9.08e+04    9.08e+04\n",
       "Cabin_B77                15.7203   4790.983      0.003      0.997   -9374.434    9405.875\n",
       "Cabin_B78                19.0060   4.63e+04      0.000      1.000   -9.07e+04    9.07e+04\n",
       "Cabin_B79                19.5646   4.63e+04      0.000      1.000   -9.08e+04    9.08e+04\n",
       "Cabin_B80                19.0060   4.63e+04      0.000      1.000   -9.07e+04    9.07e+04\n",
       "Cabin_B82 B84           -21.2864   4.64e+04     -0.000      1.000    -9.1e+04    9.09e+04\n",
       "Cabin_B86               -21.2864   4.64e+04     -0.000      1.000    -9.1e+04    9.09e+04\n",
       "Cabin_B94               -20.7277   4.64e+04     -0.000      1.000   -9.09e+04    9.09e+04\n",
       "Cabin_B96 B98            22.1625    2.6e+04      0.001      0.999   -5.09e+04    5.09e+04\n",
       "Cabin_C101               19.5646   4.63e+04      0.000      1.000   -9.08e+04    9.08e+04\n",
       "Cabin_C103               19.5646   4.63e+04      0.000      1.000   -9.08e+04    9.08e+04\n",
       "Cabin_C104               22.2531   4.64e+04      0.000      1.000    -9.1e+04     9.1e+04\n",
       "Cabin_C106               22.2531   4.64e+04      0.000      1.000    -9.1e+04     9.1e+04\n",
       "Cabin_C110              -20.7277   4.64e+04     -0.000      1.000   -9.09e+04    9.09e+04\n",
       "Cabin_C111              -21.2864   4.64e+04     -0.000      1.000    -9.1e+04    9.09e+04\n",
       "Cabin_C118              -21.1295   4.64e+04     -0.000      1.000   -9.09e+04    9.09e+04\n",
       "Cabin_C123               -0.5803      1.768     -0.328      0.743      -4.045       2.884\n",
       "Cabin_C124              -16.8817   4793.029     -0.004      0.997   -9411.046    9377.282\n",
       "Cabin_C125               17.4738   1.11e+04      0.002      0.999   -2.16e+04    2.17e+04\n",
       "Cabin_C126               19.0051   8856.139      0.002      0.998   -1.73e+04    1.74e+04\n",
       "Cabin_C128              -20.7277   4.64e+04     -0.000      1.000   -9.09e+04    9.09e+04\n",
       "Cabin_C148               21.6944   4.64e+04      0.000      1.000   -9.09e+04     9.1e+04\n",
       "Cabin_C2                 -0.5803      1.768     -0.328      0.743      -4.045       2.884\n",
       "Cabin_C22 C26            -1.7239      1.390     -1.240      0.215      -4.449       1.001\n",
       "Cabin_C23 C25 C27        -0.1928      1.318     -0.146      0.884      -2.776       2.391\n",
       "Cabin_C30               -20.7277   4.64e+04     -0.000      1.000   -9.09e+04    9.09e+04\n",
       "Cabin_C32                19.0060   4.63e+04      0.000      1.000   -9.07e+04    9.07e+04\n",
       "Cabin_C45                19.0060   4.63e+04      0.000      1.000   -9.07e+04    9.07e+04\n",
       "Cabin_C46               -20.7277   4.64e+04     -0.000      1.000   -9.09e+04    9.09e+04\n",
       "Cabin_C47                21.6944   4.64e+04      0.000      1.000   -9.09e+04     9.1e+04\n",
       "Cabin_C49               -23.9748   4.65e+04     -0.001      1.000   -9.12e+04    9.12e+04\n",
       "Cabin_C50                19.1628   4.63e+04      0.000      1.000   -9.07e+04    9.08e+04\n",
       "Cabin_C52                18.4053   4795.642      0.004      0.997   -9380.880    9417.691\n",
       "Cabin_C54                19.0060   4.63e+04      0.000      1.000   -9.07e+04    9.07e+04\n",
       "Cabin_C62 C64            19.0060   4.63e+04      0.000      1.000   -9.07e+04    9.07e+04\n",
       "Cabin_C65                -1.1379      1.778     -0.640      0.522      -4.624       2.348\n",
       "Cabin_C68                -0.9814      1.780     -0.551      0.581      -4.470       2.508\n",
       "Cabin_C7                 19.8783   4.63e+04      0.000      1.000   -9.08e+04    9.08e+04\n",
       "Cabin_C70                22.0081   4.64e+04      0.000      1.000    -9.1e+04     9.1e+04\n",
       "Cabin_C78                -0.9832      1.799     -0.547      0.585      -4.509       2.542\n",
       "Cabin_C82               -20.9727   4.64e+04     -0.000      1.000   -9.09e+04    9.09e+04\n",
       "Cabin_C83                -0.5803      1.768     -0.328      0.743      -4.045       2.884\n",
       "Cabin_C85                19.0060   4.63e+04      0.000      1.000   -9.07e+04    9.07e+04\n",
       "Cabin_C86               -21.2864   4.64e+04     -0.000      1.000    -9.1e+04    9.09e+04\n",
       "Cabin_C87               -20.7277   4.64e+04     -0.000      1.000   -9.09e+04    9.09e+04\n",
       "Cabin_C90                19.0060   4.63e+04      0.000      1.000   -9.07e+04    9.07e+04\n",
       "Cabin_C91               -20.5709   4.64e+04     -0.000      1.000   -9.09e+04    9.09e+04\n",
       "Cabin_C92                18.4236   8750.777      0.002      0.998   -1.71e+04    1.72e+04\n",
       "Cabin_C93                19.0051   8856.139      0.002      0.998   -1.73e+04    1.74e+04\n",
       "Cabin_C95               -20.7277   4.64e+04     -0.000      1.000   -9.09e+04    9.09e+04\n",
       "Cabin_C99                19.5646   4.63e+04      0.000      1.000   -9.08e+04    9.08e+04\n",
       "Cabin_D                   0.2519      1.445      0.174      0.862      -2.581       3.085\n",
       "Cabin_D10 D12            21.8513   4.64e+04      0.000      1.000    -9.1e+04     9.1e+04\n",
       "Cabin_D11                19.5646   4.63e+04      0.000      1.000   -9.08e+04    9.08e+04\n",
       "Cabin_D15                19.0060   4.63e+04      0.000      1.000   -9.07e+04    9.07e+04\n",
       "Cabin_D17                15.7203   4790.983      0.003      0.997   -9374.434    9405.875\n",
       "Cabin_D19                22.2531   4.64e+04      0.000      1.000    -9.1e+04     9.1e+04\n",
       "Cabin_D20                15.1621   4789.645      0.003      0.997   -9372.369    9402.693\n",
       "Cabin_D21                19.5646   4.63e+04      0.000      1.000   -9.08e+04    9.08e+04\n",
       "Cabin_D26               -16.7251   4792.722     -0.003      0.997   -9410.287    9376.837\n",
       "Cabin_D28                19.7215   4.63e+04      0.000      1.000   -9.08e+04    9.08e+04\n",
       "Cabin_D30               -20.7277   4.64e+04     -0.000      1.000   -9.09e+04    9.09e+04\n",
       "Cabin_D33                18.4236   8750.777      0.002      0.998   -1.71e+04    1.72e+04\n",
       "Cabin_D35                19.1672   8880.769      0.002      0.998   -1.74e+04    1.74e+04\n",
       "Cabin_D36                15.1621   4789.645      0.003      0.997   -9372.369    9402.693\n",
       "Cabin_D37                19.0060   4.63e+04      0.000      1.000   -9.07e+04    9.07e+04\n",
       "Cabin_D45                22.2531   4.64e+04      0.000      1.000    -9.1e+04     9.1e+04\n",
       "Cabin_D46               -20.7277   4.64e+04     -0.000      1.000   -9.09e+04    9.09e+04\n",
       "Cabin_D47                19.8783   4.63e+04      0.000      1.000   -9.08e+04    9.08e+04\n",
       "Cabin_D48               -20.9727   4.64e+04     -0.000      1.000   -9.09e+04    9.09e+04\n",
       "Cabin_D49                21.6944   4.64e+04      0.000      1.000   -9.09e+04     9.1e+04\n",
       "Cabin_D50               -20.7277   4.64e+04     -0.000      1.000   -9.09e+04    9.09e+04\n",
       "Cabin_D56                23.0382   4.65e+04      0.000      1.000   -9.11e+04    9.11e+04\n",
       "Cabin_D6                -20.7277   4.64e+04     -0.000      1.000   -9.09e+04    9.09e+04\n",
       "Cabin_D7                 19.5646   4.63e+04      0.000      1.000   -9.08e+04    9.08e+04\n",
       "Cabin_D9                 19.5646   4.63e+04      0.000      1.000   -9.08e+04    9.08e+04\n",
       "Cabin_E10                23.8233   4.65e+04      0.001      1.000   -9.12e+04    9.12e+04\n",
       "Cabin_E101               23.3595   1.28e+05      0.000      1.000    -2.5e+05    2.51e+05\n",
       "Cabin_E12                22.2531   4.64e+04      0.000      1.000    -9.1e+04     9.1e+04\n",
       "Cabin_E121               20.7737   9060.190      0.002      0.998   -1.77e+04    1.78e+04\n",
       "Cabin_E17                22.2531   4.64e+04      0.000      1.000    -9.1e+04     9.1e+04\n",
       "Cabin_E24                18.4053   4795.642      0.004      0.997   -9380.880    9417.691\n",
       "Cabin_E25                18.4053   4795.642      0.004      0.997   -9380.880    9417.691\n",
       "Cabin_E31               -20.7277   4.64e+04     -0.000      1.000   -9.09e+04    9.09e+04\n",
       "Cabin_E33                15.8769   4791.296      0.003      0.997   -9374.891    9406.644\n",
       "Cabin_E34                19.1628   4.63e+04      0.000      1.000   -9.07e+04    9.08e+04\n",
       "Cabin_E36                19.0060   4.63e+04      0.000      1.000   -9.07e+04    9.07e+04\n",
       "Cabin_E38               -20.7277   4.64e+04     -0.000      1.000   -9.09e+04    9.09e+04\n",
       "Cabin_E40                19.0060   4.63e+04      0.000      1.000   -9.07e+04    9.07e+04\n",
       "Cabin_E44                -0.5803      1.768     -0.328      0.743      -4.045       2.884\n",
       "Cabin_E46               -20.7277   4.64e+04     -0.000      1.000   -9.09e+04    9.09e+04\n",
       "Cabin_E49                19.1628   4.63e+04      0.000      1.000   -9.07e+04    9.08e+04\n",
       "Cabin_E50                21.6944   4.64e+04      0.000      1.000   -9.09e+04     9.1e+04\n",
       "Cabin_E58               -20.7277   4.64e+04     -0.000      1.000   -9.09e+04    9.09e+04\n",
       "Cabin_E63               -20.7277   4.64e+04     -0.000      1.000   -9.09e+04    9.09e+04\n",
       "Cabin_E67                -0.4238      1.769     -0.240      0.811      -3.891       3.044\n",
       "Cabin_E68                19.8783   4.63e+04      0.000      1.000   -9.08e+04    9.08e+04\n",
       "Cabin_E77               -22.6310   4.65e+04     -0.000      1.000   -9.11e+04     9.1e+04\n",
       "Cabin_E8                 19.0051   8856.139      0.002      0.998   -1.73e+04    1.74e+04\n",
       "Cabin_F E69              20.7331   4.64e+04      0.000      1.000   -9.09e+04    9.09e+04\n",
       "Cabin_F G63             -19.1575   4.63e+04     -0.000      1.000   -9.07e+04    9.07e+04\n",
       "Cabin_F G73             -15.3139   4790.050     -0.003      0.997   -9403.639    9373.011\n",
       "Cabin_F2                  2.4472      1.245      1.966      0.049       0.007       4.887\n",
       "Cabin_F33                26.0038   4.52e+05   5.75e-05      1.000   -8.86e+05    8.86e+05\n",
       "Cabin_F38               -19.5615   4.63e+04     -0.000      1.000   -9.08e+04    9.08e+04\n",
       "Cabin_F4                 19.9703   8969.642      0.002      0.998   -1.76e+04    1.76e+04\n",
       "Cabin_G6                 -0.1597      1.016     -0.157      0.875      -2.152       1.832\n",
       "Cabin_T                 -20.7277   4.64e+04     -0.000      1.000   -9.09e+04    9.09e+04\n",
       "Embarked_Q               -0.1547      0.399     -0.387      0.698      -0.937       0.628\n",
       "Embarked_S               -0.5576      0.276     -2.023      0.043      -1.098      -0.017\n",
       "=========================================================================================\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.18 of observations can be\n",
       "perfectly predicted. This might indicate that there is complete\n",
       "quasi-separation. In this case some parameters will not be identified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const         2.612070e+01\n",
       "Pclass        4.569063e-01\n",
       "Parch         8.551303e-01\n",
       "Sex_male      6.834911e-02\n",
       "Cabin_A14     9.955357e-10\n",
       "                  ...     \n",
       "Cabin_F4      4.709882e+08\n",
       "Cabin_G6      8.523761e-01\n",
       "Cabin_T       9.955357e-10\n",
       "Embarked_Q    8.566777e-01\n",
       "Embarked_S    5.725971e-01\n",
       "Length: 152, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(result.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your analysis here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level - up\n",
    "\n",
    "Create a new model, this time only using those features you determined were influential based on your analysis in step 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Your code here\n",
    "x_feats = ['Pclass','Sex','Parch','Age'] #age didn't work\n",
    "X = pd.get_dummies(data[x_feats], drop_first=True, dtype=float)\n",
    "y = pd.get_dummies(data[\"Survived\"], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingDataError",
     "evalue": "exog contains inf or nans",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mMissingDataError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-2c1c8b58176e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mlogit_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# get results of the fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/statsmodels/discrete/discrete_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBinaryModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m         if (not issubclass(self.__class__, MultinomialModel) and\n\u001b[1;32m    431\u001b[0m                 not np.all((self.endog >= 0) & (self.endog <= 1))):\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/statsmodels/discrete/discrete_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \"\"\"\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDiscreteModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_on_perfect_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLikelihoodModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mhasconst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hasconst'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         self.data = self._handle_data(endog, exog, missing, hasconst,\n\u001b[0;32m---> 68\u001b[0;31m                                       **kwargs)\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_constant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_constant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36m_handle_data\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhasconst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhasconst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;31m# kwargs arrays could have changed, easier to just attach here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/statsmodels/base/data.py\u001b[0m in \u001b[0;36mhandle_data\u001b[0;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m     \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_data_class_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     return klass(endog, exog=exog, missing=missing, hasconst=hasconst,\n\u001b[0;32m--> 635\u001b[0;31m                  **kwargs)\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/statsmodels/base/data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconst_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_constant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_constant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhasconst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/statsmodels/base/data.py\u001b[0m in \u001b[0;36m_handle_constant\u001b[0;34m(self, hasconst)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mptp_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mptp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mptp_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mMissingDataError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exog contains inf or nans'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             \u001b[0mconst_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mptp_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_constant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconst_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMissingDataError\u001b[0m: exog contains inf or nans"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# create intercept term required for sm.Logit, see documentation for more information\n",
    "X = sm.add_constant(X)\n",
    "# fit model\n",
    "logit_model = sm.Logit(y.iloc[:,1], X)\n",
    "# get results of the fit\n",
    "result = logit_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>1</td>        <th>  No. Observations:  </th>  <td>   891</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   885</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     5</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 12 May 2020</td> <th>  Pseudo R-squ.:     </th>  <td>0.3101</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>02:28:52</td>     <th>  Log-Likelihood:    </th> <td> -409.35</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -593.33</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>2.388e-77</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>      <td>    3.7182</td> <td>    0.341</td> <td>   10.895</td> <td> 0.000</td> <td>    3.049</td> <td>    4.387</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pclass</th>     <td>   -0.9313</td> <td>    0.111</td> <td>   -8.379</td> <td> 0.000</td> <td>   -1.149</td> <td>   -0.713</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Parch</th>      <td>   -0.1270</td> <td>    0.105</td> <td>   -1.209</td> <td> 0.227</td> <td>   -0.333</td> <td>    0.079</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sex_male</th>   <td>   -2.6842</td> <td>    0.194</td> <td>  -13.846</td> <td> 0.000</td> <td>   -3.064</td> <td>   -2.304</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Embarked_Q</th> <td>   -0.2073</td> <td>    0.367</td> <td>   -0.565</td> <td> 0.572</td> <td>   -0.927</td> <td>    0.512</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Embarked_S</th> <td>   -0.5484</td> <td>    0.224</td> <td>   -2.446</td> <td> 0.014</td> <td>   -0.988</td> <td>   -0.109</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      1   No. Observations:                  891\n",
       "Model:                          Logit   Df Residuals:                      885\n",
       "Method:                           MLE   Df Model:                            5\n",
       "Date:                Tue, 12 May 2020   Pseudo R-squ.:                  0.3101\n",
       "Time:                        02:28:52   Log-Likelihood:                -409.35\n",
       "converged:                       True   LL-Null:                       -593.33\n",
       "Covariance Type:            nonrobust   LLR p-value:                 2.388e-77\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          3.7182      0.341     10.895      0.000       3.049       4.387\n",
       "Pclass        -0.9313      0.111     -8.379      0.000      -1.149      -0.713\n",
       "Parch         -0.1270      0.105     -1.209      0.227      -0.333       0.079\n",
       "Sex_male      -2.6842      0.194    -13.846      0.000      -3.064      -2.304\n",
       "Embarked_Q    -0.2073      0.367     -0.565      0.572      -0.927       0.512\n",
       "Embarked_S    -0.5484      0.224     -2.446      0.014      -0.988      -0.109\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "Well done! In this lab, you practiced using statsmodels to build a logistic regression model. You then reviewed interpreting the results, building upon your previous stats knowledge, similar to linear regression. Continue on to take a look at building logistic regression models in Sci-kit learn!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
